# ğŸ§‘â€ğŸ« Teacher Performance AI Assistant

An AI-powered teacher assistant that answers key questions about student performance using descriptive analytics, predictive modeling, and prescriptive recommendations â€” delivered through a chat-based interface and interactive UI.

This project demonstrates applied machine learning, AI system design, analytics engineering, and scalable backend development in an education-focused use case.

---

## ğŸ¯ Problem

Teachers frequently need fast, reliable answers to performance questions such as:

1. How is student X doing in my course?
2. What is pulling student Yâ€™s grade down?
3. Which students are struggling?
4. What assignments are students struggling with most?
5. How will student Z perform by the end of the course?
6. If student A is failing, what specific actions can help them reach passing?

This assistant transforms raw student signals into actionable insight.

> âš ï¸ All data in this repository is synthetic and generated programmatically.

---

## ğŸ§  What This Project Demonstrates

- Requirement-driven AI development
- Tool-based AI chat orchestration
- Predictive analytics (final grade forecasting)
- Prescriptive analytics (targeted intervention recommendations)
- Descriptive analytics (course and student insights)
- Modular backend architecture (FastAPI)
- Teacher-facing UI (Streamlit)
- API load testing (Locust)
- CI integration (GitHub Actions)

---

## ğŸ— Architecture Overview

```
Teacher-Performance-AI-Assistant/
â”‚
â”œâ”€â”€ backend/                # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py         # API entrypoint
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ analytics.py
â”‚   â”‚       â”œâ”€â”€ predictive.py
â”‚   â”‚       â”œâ”€â”€ prescriptive.py
â”‚   â”‚       â”œâ”€â”€ rag.py
â”‚   â”‚       â””â”€â”€ chat_orchestrator.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ui/                     # Streamlit teacher UI
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ generate_synthetic_data.py
â”‚
â”œâ”€â”€ loadtest/
â”‚   â””â”€â”€ locustfile.py
â”‚
â””â”€â”€ data/
    â””â”€â”€ synthetic_course_data.csv
```

### System Flow

1. Teacher submits question in chat UI
2. Backend detects intent
3. Request is routed to analytics/predictive/prescriptive service
4. Model or rules generate response
5. Structured answer returned with suggested follow-ups

This mirrors real AI agent architecture with tool routing.

---

## ğŸ“Š Analytics Capabilities

### 1ï¸âƒ£ Descriptive Analytics
- Student performance snapshot
- Grade component breakdown
- Identification of struggling students
- Identification of hardest assignments

### 2ï¸âƒ£ Predictive Analytics
- RandomForest regression model predicts final grade
- Probability of failing derived from predicted grade
- Portfolio-friendly approach that balances interpretability and performance

### 3ï¸âƒ£ Prescriptive Analytics
- Structured intervention recommendations
- Prioritized by impact (attendance, missing work, exam weakness, etc.)
- Designed for explainability and actionability

---

## ğŸ§ª Synthetic Dataset

The dataset simulates:
- Attendance patterns
- Missing assignments
- Late submissions
- Quiz/homework/exam averages
- Platform engagement
- Assignment difficulty and submission rates

Generated using:

```bash
python scripts/generate_synthetic_data.py
```

No real student data is used.

---

## ğŸš€ How to Run (On Your Personal Machine)

### Step 1 â€” Generate Data

```bash
python scripts/generate_synthetic_data.py
```

Creates:

```
data/synthetic_course_data.csv
```

---

### Step 2 â€” Start Backend API

Install backend dependencies:

```bash
pip install -r backend/requirements.txt
```

Run API:

```bash
uvicorn backend.app.main:app --reload
```

Health check:

```
http://localhost:8000/health
```

---

### Step 3 â€” Start Teacher UI

Open a new terminal:

```bash
pip install -r ui/requirements.txt
streamlit run ui/streamlit_app.py
```

---

## ğŸ’¬ Example Prompts

Use course IDs like `C1` and student IDs like `S100100`.

- How is student S100100 doing in my course?
- What is pulling student S100120's grade down?
- Which students are struggling?
- What are the hardest assignments in this course?
- How will student S100100 do by the end of the course?
- Given student S100120 is failing, what recommendations can help?

---

## ğŸ“ˆ Load Testing

This project includes a Locust load test for scalability simulation.

Install Locust:

```bash
pip install locust
```

Run load test:

```bash
locust -f loadtest/locustfile.py --host http://localhost:8000
```

This simulates multiple teachers interacting with the assistant.

---

## ğŸ”¬ Model Strategy

- Model Type: RandomForestRegressor
- Features:
  - Current grade
  - Attendance rate
  - Missing assignments
  - Late submissions
  - Quiz/HW/Exam averages
  - Engagement signals
- Target:
  - Final course grade

Failure probability is derived using a smooth logistic-style mapping around the pass threshold.

This approach is intentionally interpretable and extensible.

---

## ğŸ›  Tech Stack

- Python 3.10+
- FastAPI
- Streamlit
- scikit-learn
- pandas / numpy
- Uvicorn
- Locust (load testing)
- GitHub Actions (CI)

---

## ğŸ“Œ Why This Project Is Portfolio-Ready

This repository demonstrates:

- End-to-end AI system design
- Clean modular architecture
- Predictive + prescriptive reasoning
- Chat-based AI orchestration
- Backend + UI integration
- Testing and CI
- Scalability awareness

It reflects how AI systems are built in production environments, not just notebooks.

---

## ğŸ”® Future Enhancements

- Replace heuristic routing with LLM function-calling agent
- Add real RAG with embeddings and vector store
- Improve model calibration
- Add user authentication
- Containerize with Docker
- Deploy to cloud infrastructure

---

## ğŸ“„ Disclaimer

All data in this project is synthetic and generated for demonstration purposes only.
